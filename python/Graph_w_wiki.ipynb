{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e575d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import wikipediaapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "986b940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load artist data\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/freiraum-bq/Music_Project/main/data/raw/neo4j_artists.csv\")\n",
    "artists = df[['common_name', 'wiki_url']]\n",
    "\n",
    "# Drop rows where wiki_url is NaN or an empty string\n",
    "artists = artists[artists['wiki_url'].notna() & (artists['wiki_url'] != '')]\n",
    "wiki = wikipediaapi.Wikipedia(user_agent=\"MusicGraphExample (research@example.com)\", language=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ae0ea97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 200 / 5828 artists...\n",
      "Processed 400 / 5828 artists...\n",
      "Processed 600 / 5828 artists...\n",
      "Processed 800 / 5828 artists...\n",
      "Processed 1000 / 5828 artists...\n",
      "Processed 1200 / 5828 artists...\n",
      "Processed 1400 / 5828 artists...\n",
      "Processed 1600 / 5828 artists...\n",
      "Processed 1800 / 5828 artists...\n",
      "Processed 2000 / 5828 artists...\n",
      "Processed 2200 / 5828 artists...\n",
      "Processed 2400 / 5828 artists...\n",
      "Processed 2600 / 5828 artists...\n",
      "Processed 2800 / 5828 artists...\n",
      "Processed 3000 / 5828 artists...\n",
      "Processed 3200 / 5828 artists...\n",
      "Processed 3400 / 5828 artists...\n",
      "Processed 3600 / 5828 artists...\n",
      "Processed 3800 / 5828 artists...\n",
      "Processed 4000 / 5828 artists...\n",
      "Processed 4200 / 5828 artists...\n",
      "Processed 4400 / 5828 artists...\n",
      "Processed 4600 / 5828 artists...\n",
      "Processed 4800 / 5828 artists...\n",
      "Processed 5000 / 5828 artists...\n",
      "Processed 5200 / 5828 artists...\n",
      "Processed 5400 / 5828 artists...\n",
      "Processed 5600 / 5828 artists...\n",
      "Processed 5800 / 5828 artists...\n",
      "Processed 5828 / 5828 artists...\n",
      "Graph built with 5828 nodes and 10086 edges.\n"
     ]
    }
   ],
   "source": [
    "import wikipediaapi\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "artist_urls = dict(zip(artists['common_name'], artists['wiki_url']))\n",
    "url_to_artist = {url: name for name, url in artist_urls.items()}\n",
    "\n",
    "import wikipediaapi\n",
    "import networkx as nx\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "import time\n",
    "\n",
    "artist_urls = dict(zip(artists['common_name'], artists['wiki_url']))\n",
    "url_to_artist = {url: name for name, url in artist_urls.items()}\n",
    "\n",
    "def get_page_links(url):\n",
    "    tries = 3\n",
    "    wiki = wikipediaapi.Wikipedia(user_agent=\"MusicGraphExample (research@example.com)\", language=\"en\")\n",
    "    for attempt in range(tries):\n",
    "        try:\n",
    "            if '/wiki/' not in url:\n",
    "                return url, set()\n",
    "            page_title = url.split('/wiki/')[-1]\n",
    "            page = wiki.page(page_title)\n",
    "            if not page.exists():\n",
    "                return url, set()\n",
    "            links = page.links.keys()\n",
    "            full_urls = {f\"https://en.wikipedia.org/wiki/{link}\" for link in links}\n",
    "            return url, full_urls\n",
    "        except Exception as e:\n",
    "            if attempt == tries - 1:\n",
    "                print(f\"Exception in get_page_links for url {url}: {e}\")\n",
    "                return url, set()\n",
    "            else:\n",
    "                time.sleep(2 ** attempt)\n",
    "\n",
    "def build_graph_threaded(artist_urls, url_to_artist, max_workers=10, batch_print=200):\n",
    "    G = nx.DiGraph()\n",
    "    artist_names = list(artist_urls.keys())\n",
    "    total = len(artist_names)\n",
    "    lock = threading.Lock()\n",
    "    progress = {'count': 0}\n",
    "\n",
    "    for artist in artist_names:\n",
    "        G.add_node(artist)\n",
    "\n",
    "    def worker(artist):\n",
    "        url = artist_urls[artist]\n",
    "        url, linked_urls = get_page_links(url)\n",
    "        edges = []\n",
    "        for linked_url in linked_urls:\n",
    "            if linked_url in url_to_artist and linked_url != url:\n",
    "                mentioned_artist = url_to_artist[linked_url]\n",
    "                edges.append((artist, mentioned_artist))\n",
    "        with lock:\n",
    "            progress['count'] += 1\n",
    "            if progress['count'] % batch_print == 0 or progress['count'] == total:\n",
    "                print(f\"Processed {progress['count']} / {total} artists...\")\n",
    "        return edges\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = executor.map(worker, artist_names)\n",
    "\n",
    "        for edges in results:\n",
    "            for u, v in edges:\n",
    "                G.add_edge(u, v, relation='MENTIONS')\n",
    "\n",
    "    print(f\"Graph built with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "    return G\n",
    "\n",
    "# Usage example:\n",
    "G = build_graph_threaded(artist_urls, url_to_artist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08da718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to fetch Wikipedia pages for all artists...\n",
      "Fetched Wikipedia pages for 200 artists out of 5871\n",
      "Fetched Wikipedia pages for 400 artists out of 5871\n",
      "Fetched Wikipedia pages for 600 artists out of 5871\n",
      "Fetched Wikipedia pages for 800 artists out of 5871\n",
      "Fetched Wikipedia pages for 1000 artists out of 5871\n",
      "Fetched Wikipedia pages for 1200 artists out of 5871\n",
      "Fetched Wikipedia pages for 1400 artists out of 5871\n",
      "Fetched Wikipedia pages for 1600 artists out of 5871\n",
      "Fetched Wikipedia pages for 1800 artists out of 5871\n",
      "Fetched Wikipedia pages for 2000 artists out of 5871\n",
      "Fetched Wikipedia pages for 2200 artists out of 5871\n",
      "Fetched Wikipedia pages for 2400 artists out of 5871\n",
      "Fetched Wikipedia pages for 2600 artists out of 5871\n",
      "Fetched Wikipedia pages for 2800 artists out of 5871\n",
      "Fetched Wikipedia pages for 3000 artists out of 5871\n",
      "Fetched Wikipedia pages for 3200 artists out of 5871\n",
      "Fetched Wikipedia pages for 3400 artists out of 5871\n",
      "Fetched Wikipedia pages for 3600 artists out of 5871\n",
      "Fetched Wikipedia pages for 3800 artists out of 5871\n",
      "Fetched Wikipedia pages for 4000 artists out of 5871\n",
      "Fetched Wikipedia pages for 4200 artists out of 5871\n",
      "Fetched Wikipedia pages for 4400 artists out of 5871\n",
      "Fetched Wikipedia pages for 4600 artists out of 5871\n",
      "Fetched Wikipedia pages for 4800 artists out of 5871\n",
      "Fetched Wikipedia pages for 5000 artists out of 5871\n",
      "Fetched Wikipedia pages for 5200 artists out of 5871\n",
      "Fetched Wikipedia pages for 5400 artists out of 5871\n",
      "Fetched Wikipedia pages for 5600 artists out of 5871\n",
      "Fetched Wikipedia pages for 5800 artists out of 5871\n",
      "Finished fetching Wikipedia pages.\n"
     ]
    }
   ],
   "source": [
    "# # loads entire wiki\n",
    "# import pandas as pd\n",
    "# import wikipediaapi\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "# import threading\n",
    "# import time\n",
    "\n",
    "# # Prepare artist names list\n",
    "# artist_names = artists['common_name'].tolist()\n",
    "\n",
    "# def fetch_all_pages(artist_names, wiki):\n",
    "#     wiki_texts = {}\n",
    "#     lock = threading.Lock()\n",
    "#     progress = {'count': 0}\n",
    "\n",
    "#     def fetch_page(artist):\n",
    "#         tries = 3\n",
    "#         for attempt in range(tries):\n",
    "#             try:\n",
    "#                 page = wiki.page(artist)\n",
    "#                 text = page.text if page.exists() else None\n",
    "#                 break\n",
    "#             except Exception as e:\n",
    "#                 if attempt == tries - 1:\n",
    "#                     text = None\n",
    "#                 else:\n",
    "#                     time.sleep(2 ** attempt)\n",
    "#         with lock:\n",
    "#             wiki_texts[artist] = text\n",
    "#             progress['count'] += 1\n",
    "#             if progress['count'] % 200 == 0:\n",
    "#                 print(f\"Fetched Wikipedia pages for {progress['count']} artists out of {len(artist_names)}\")\n",
    "#         return\n",
    "\n",
    "#     with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "#         executor.map(fetch_page, artist_names)\n",
    "\n",
    "#     return wiki_texts\n",
    "\n",
    "# print(\"Starting to fetch Wikipedia pages for all artists...\")\n",
    "# wiki_texts = fetch_all_pages(artist_names, wiki)\n",
    "# print(\"Finished fetching Wikipedia pages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf2078d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 5828\n",
      "Edges: 10086\n",
      "Top-10 most-mentioned artists:\n",
      "Adele: mentioned by 389 pages\n",
      "Beyonc√©: mentioned by 373 pages\n",
      "U2: mentioned by 358 pages\n",
      "Eminem: mentioned by 316 pages\n",
      "Madonna: mentioned by 312 pages\n",
      "Metallica: mentioned by 254 pages\n",
      "Aerosmith: mentioned by 242 pages\n",
      "Coldplay: mentioned by 242 pages\n",
      "Rihanna: mentioned by 240 pages\n",
      "Bono: mentioned by 225 pages\n"
     ]
    }
   ],
   "source": [
    "# Basic stats\n",
    "print(\"Nodes:\", G.number_of_nodes())\n",
    "print(\"Edges:\", G.number_of_edges())\n",
    "\n",
    "# Count mentions: who is mentioned most (incoming edges)\n",
    "mention_count = Counter(v for _, v in G.edges())\n",
    "top10 = mention_count.most_common(10)\n",
    "\n",
    "print(\"Top-10 most-mentioned artists:\")\n",
    "for name, cnt in top10:\n",
    "    print(f\"{name}: mentioned by {cnt} pages\")\n",
    "    print (\"eminem, yay. No taylor swift cuz she traaaash\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
