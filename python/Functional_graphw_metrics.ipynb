{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b8f40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "df_orig = pd.read_csv(\"originals.csv\")\n",
    "df_cov = pd.read_csv(\"covers.csv\")\n",
    "\n",
    "# Create the graph\n",
    "G = nx.DiGraph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dade6376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sidney Bechet' 'Dan Hartman' 'Van Morrison' ...\n",
      " 'Annie Ross & The Low Note Quintet' 'Teitur' 'Can']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_try=np.array(df_orig['org_art_name'])\n",
    "\n",
    "print(df_try)\n",
    "# Add artist nodes\n",
    "for artist_name in df_try:\n",
    "    G.add_node(artist_name, type='Artist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caa2400e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17975"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fc02ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        song_title  cov_art_id org_art_id\n",
      "0     Petite fleur       [879]        [1]\n",
      "1   Evil Gal Blues        [10]        [8]\n",
      "2   Evil Gal Blues         [9]        [8]\n",
      "3  Big Yellow Taxi  [20, 1912]     [5191]\n",
      "4    Light My Fire        [21]       [16]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Merge on perf_id, keep only cov_art_id and org_art_id\n",
    "df_merged = pd.merge(df_cov[['song_title', 'cov_art_id']], \n",
    "                     df_orig[['song_title', 'org_art_id']], \n",
    "                     on='song_title', \n",
    "                     how='inner')\n",
    "\n",
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4122554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 song_title cov_art_id org_art_id\n",
      "0              Petite fleur        879          1\n",
      "1            Evil Gal Blues         10          8\n",
      "2            Evil Gal Blues          9          8\n",
      "3           Big Yellow Taxi         20       5191\n",
      "4           Big Yellow Taxi       1912       5191\n",
      "...                     ...        ...        ...\n",
      "584171         Modern Music      35611      17062\n",
      "584172      Surabaya Johnny      14339       2437\n",
      "584173          Being Alive      14339      69125\n",
      "584174          Being Alive      14339      69125\n",
      "584175  Yesterday Once More        894       1389\n",
      "\n",
      "[584176 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Step 1: Parse stringified lists if needed\n",
    "def parse_list(val):\n",
    "    if isinstance(val, str):\n",
    "        try:\n",
    "            return ast.literal_eval(val)\n",
    "        except:\n",
    "            return [val]\n",
    "    return val\n",
    "\n",
    "df_merged['cov_art_id'] = df_merged['cov_art_id'].apply(parse_list)\n",
    "df_merged['org_art_id'] = df_merged['org_art_id'].apply(parse_list)\n",
    "\n",
    "# Step 2: Explode both columns\n",
    "df_exploded = df_merged.explode('cov_art_id').explode('org_art_id').reset_index(drop=True)\n",
    "print(df_exploded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f0fe1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_count = 0\n",
    "for _, row in df_merged.iterrows():\n",
    "    covering_artists = row['cov_art_id']\n",
    "    original_artists = row['org_art_id']\n",
    "\n",
    "    # Create edges for every pair (covering -> original)\n",
    "    for cov_id in covering_artists:\n",
    "        for org_id in original_artists:\n",
    "            if cov_id != org_id:  # avoid self-loop\n",
    "                G.add_edge(cov_id, org_id, relation='COVERED')\n",
    "                edge_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "507237cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499454"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2edea5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter()\n",
      "[(41, 4252), (243, 2261), (319, 2184), (4305, 2116), (158, 2058), (11023, 1885), (1535, 1706), (2232, 1701), (61, 1556), (2575, 1551)]\n",
      "41: covered 4252 times\n",
      "243: covered 2261 times\n",
      "319: covered 2184 times\n",
      "4305: covered 2116 times\n",
      "158: covered 2058 times\n",
      "11023: covered 1885 times\n",
      "1535: covered 1706 times\n",
      "2232: covered 1701 times\n",
      "61: covered 1556 times\n",
      "2575: covered 1551 times\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "# Step 2: Count how many times each artist is covered\n",
    "cover_count = collections.Counter()\n",
    "print(cover_count)\n",
    "for u, v, data in G.edges(data=True):\n",
    "    if data.get('relation') == 'COVERED':\n",
    "        cover_count[v] += 1  # v = original artist who was covered\n",
    "\n",
    "# Step 3: Get top 10 most covered artists\n",
    "top_10_covered = cover_count.most_common(10)\n",
    "print(top_10_covered)\n",
    "\n",
    "# Step 4: Print them\n",
    "for artist, count in top_10_covered:\n",
    "    print(f\"{artist}: covered {count} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "975b052b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41, 243, 319, 4305, 158, 11023, 1535, 2232, 61, 2575]\n"
     ]
    }
   ],
   "source": [
    "# Extract only the artist IDs (integers)\n",
    "top_10_artist_ids = [artist_id for artist_id, count in top_10_covered]\n",
    "print(top_10_artist_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a1eb334d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            org_art_name org_art_id\n",
      "0                          Sidney Bechet          1\n",
      "1                            Dan Hartman       5483\n",
      "2                           Van Morrison          6\n",
      "3                       Dinah Washington          8\n",
      "4                            The Regents         13\n",
      "...                                  ...        ...\n",
      "61807                  The Four Freshmen      14202\n",
      "61808                          Judy Lynn     100685\n",
      "61809  Annie Ross & The Low Note Quintet       2442\n",
      "61810                             Teitur      50123\n",
      "61811                                Can      17460\n",
      "\n",
      "[61812 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joynt\\AppData\\Local\\Temp\\ipykernel_8652\\1392870795.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ids_and_names['org_art_id'] = df_ids_and_names['org_art_id'].apply(parse_list)\n"
     ]
    }
   ],
   "source": [
    "# no real reason for this other than to convert everything to a string\n",
    "# Merge on perf_id, keep only cov_art_id and org_art_id\n",
    "df_ids_and_names=df_orig[['org_art_name', 'org_art_id']]\n",
    "\n",
    "# Step 1: Parse stringified lists if needed\n",
    "def parse_list(val):\n",
    "    if isinstance(val, str):\n",
    "        try:\n",
    "            return ast.literal_eval(val)\n",
    "        except:\n",
    "            return [val]\n",
    "    return val\n",
    "\n",
    "df_ids_and_names['org_art_id'] = df_ids_and_names['org_art_id'].apply(parse_list)\n",
    "\n",
    "\n",
    "# Step 2: Explode both columns\n",
    "df_id_names_exploded = df_ids_and_names.explode('org_art_id').reset_index(drop=True)\n",
    "print(df_id_names_exploded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "639725ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  original_name artist_id  times covered\n",
      "20                                  The Beatles        41           4252\n",
      "35                                   Will Smith        61           2261\n",
      "107                                   Bob Dylan       158           2184\n",
      "330                                  Diana Ross     11023           2116\n",
      "603                    Bing Crosby, Grace Kelly       243           2058\n",
      "1050                                 The Troggs      1535           1885\n",
      "1668   Mae West & Duke Ellington, His Orchestra      4305           1706\n",
      "1696                               Fred Astaire      2232           1701\n",
      "1760                              Frank Sinatra       319           1556\n",
      "13581                               The Sundays      2575           1551\n"
     ]
    }
   ],
   "source": [
    "artist_ids = [41, 243, 319, 4305, 158, 11023, 1535, 2232, 61, 2575]\n",
    "artist_ids_str = [str(x) for x in artist_ids]\n",
    "\n",
    "# Filter rows where org_art_id (as string) matches any artist_id string\n",
    "matches = df_id_names_exploded[df_id_names_exploded['org_art_id'].astype(str).isin(artist_ids_str)]\n",
    "\n",
    "# Drop duplicates to keep only the first instance of each artist_id\n",
    "matches_unique = matches.drop_duplicates(subset='org_art_id')\n",
    "\n",
    "# Select and rename columns\n",
    "counts = [count for _, count in top_10_covered]\n",
    "result_df = matches_unique[['org_art_name', 'org_art_id']].copy()\n",
    "result_df.columns = ['original_name', 'artist_id']\n",
    "result_df[\"times covered\"]=counts\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37caee2a",
   "metadata": {},
   "source": [
    "pagerank centrality metric\n",
    "importance based on network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c2f4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 76356\n",
      "Edges: 499454\n"
     ]
    }
   ],
   "source": [
    "print(\"Nodes:\", G.number_of_nodes())\n",
    "print(\"Edges:\", G.number_of_edges())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4c3bc2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41, 158, 206, 616, 90, 297, 194, 604, 243, 277]\n"
     ]
    }
   ],
   "source": [
    "# Compute PageRank\n",
    "pagerank_scores = nx.pagerank(G, alpha=0.85) # is a default\n",
    "# # Sort and get top 10\n",
    "top_10_pagerank = sorted(pagerank_scores.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "pagerank_results=np.array([\"top ten pagerank\"])\n",
    "\n",
    "# Extract just the artist IDs into a list\n",
    "pagerank_results= [artist_id for artist_id, score in top_10_pagerank]\n",
    "print(pagerank_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e4957ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['41', '158', '206', '616', '90', '297', '194', '604', '243', '277']\n",
      "                 original_name artist_id\n",
      "20                 The Beatles        41\n",
      "48      The Velvet Underground        90\n",
      "107                  Bob Dylan       158\n",
      "127                David Bowie       194\n",
      "150         The Rolling Stones       206\n",
      "200                The Stooges       277\n",
      "473                    Ramones       604\n",
      "495               Depeche Mode       616\n",
      "603   Bing Crosby, Grace Kelly       243\n",
      "1410                        U2       297\n"
     ]
    }
   ],
   "source": [
    "pagerank_results = [str(i) for i in pagerank_results]\n",
    "print(pagerank_results)\n",
    "# Filter rows where org_art_id (as string) matches any artist_id string\n",
    "matches = df_id_names_exploded[df_id_names_exploded['org_art_id'].astype(str).isin(pagerank_results)]\n",
    "\n",
    "# Drop duplicates to keep only the first instance of each artist_id\n",
    "matches_unique = matches.drop_duplicates(subset='org_art_id')\n",
    "\n",
    "# Select and rename columns\n",
    "counts = [count for _, count in top_10_covered]\n",
    "pagerank_result_new = matches_unique[['org_art_name', 'org_art_id']].copy()\n",
    "pagerank_result_new.columns = ['original_name', 'artist_id']\n",
    "print(pagerank_result_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c74463",
   "metadata": {},
   "source": [
    "In-degree Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7196ecf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41, 243, 319, 4305, 158, 11023, 1535, 2232, 61, 2575]\n"
     ]
    }
   ],
   "source": [
    "# Compute in-degree centrality (for directed graphs)\n",
    "in_degree_centrality = nx.in_degree_centrality(G)\n",
    "\n",
    "# Sort and get top 10 nodes by in-degree centrality\n",
    "in_degree_centrality_results= sorted(in_degree_centrality.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "# Extract just the artist IDs into a list\n",
    "in_degree_centrality_results= [artist_id for artist_id, score in in_degree_centrality_results]\n",
    "print(in_degree_centrality_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8a67981c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['41', '243', '319', '4305', '158', '11023', '1535', '2232', '61', '2575']\n",
      "                                  original_name artist_id\n",
      "20                                  The Beatles        41\n",
      "35                                   Will Smith        61\n",
      "107                                   Bob Dylan       158\n",
      "330                                  Diana Ross     11023\n",
      "603                    Bing Crosby, Grace Kelly       243\n",
      "1050                                 The Troggs      1535\n",
      "1668   Mae West & Duke Ellington, His Orchestra      4305\n",
      "1696                               Fred Astaire      2232\n",
      "1760                              Frank Sinatra       319\n",
      "13581                               The Sundays      2575\n"
     ]
    }
   ],
   "source": [
    "in_degree_centrality_results = [str(i) for i in in_degree_centrality_results]\n",
    "print(in_degree_centrality_results)\n",
    "# Filter rows where org_art_id (as string) matches any artist_id string\n",
    "matches = df_id_names_exploded[df_id_names_exploded['org_art_id'].astype(str).isin(in_degree_centrality_results)]\n",
    "\n",
    "# Drop duplicates to keep only the first instance of each artist_id\n",
    "matches_unique = matches.drop_duplicates(subset='org_art_id')\n",
    "\n",
    "# Select and rename columns\n",
    "counts = [count for _, count in top_10_covered]\n",
    "in_degree_centrality_results_new = matches_unique[['org_art_name', 'org_art_id']].copy()\n",
    "in_degree_centrality_results_new.columns = ['original_name', 'artist_id']\n",
    "print(in_degree_centrality_results_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0d07b7",
   "metadata": {},
   "source": [
    "Betweenness Centrality\n",
    "\n",
    "Nodes that control flow / connectors\n",
    "\n",
    "Example in Your Music Network Context\n",
    "Betweenness could highlight artists who link different genres or scenes by covering songs from multiple communities.\n",
    "\n",
    "Artists who bridge otherwise disconnected groups or influence multiple clusters.\n",
    "\n",
    "They might not be the most covered (high in-degree) but have strategic importance connecting parts of the network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "697f90aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41, 158, 10, 319, 103, 206, 148, 243, 618, 6492]\n"
     ]
    }
   ],
   "source": [
    "# Approximate betweenness using a sample of nodes\n",
    "# note: run time is insane otherwise (could take days), thus k set low\n",
    "betweenness = nx.betweenness_centrality(G, k=100)  # try k=500 or lower\n",
    "\n",
    "# Sort nodes by betweenness centrality descending and take top 10\n",
    "top_10_betweenness = sorted(betweenness.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "# Extract just the artist IDs into a list\n",
    "betweenness_centrality_results= [artist_id for artist_id, score in top_10_betweenness]\n",
    "print(betweenness_centrality_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e8155324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['41', '243', '319', '4305', '158', '11023', '1535', '2232', '61', '2575']\n",
      "                                  original_name artist_id\n",
      "20                                  The Beatles        41\n",
      "35                                   Will Smith        61\n",
      "107                                   Bob Dylan       158\n",
      "330                                  Diana Ross     11023\n",
      "603                    Bing Crosby, Grace Kelly       243\n",
      "1050                                 The Troggs      1535\n",
      "1668   Mae West & Duke Ellington, His Orchestra      4305\n",
      "1696                               Fred Astaire      2232\n",
      "1760                              Frank Sinatra       319\n",
      "13581                               The Sundays      2575\n"
     ]
    }
   ],
   "source": [
    "betweenness_centrality_results = [str(i) for i in in_degree_centrality_results]\n",
    "print(betweenness_centrality_results)\n",
    "# Filter rows where org_art_id (as string) matches any artist_id string\n",
    "matches = df_id_names_exploded[df_id_names_exploded['org_art_id'].astype(str).isin(betweenness_centrality_results)]\n",
    "\n",
    "# Drop duplicates to keep only the first instance of each artist_id\n",
    "matches_unique = matches.drop_duplicates(subset='org_art_id')\n",
    "\n",
    "# Select and rename columns\n",
    "counts = [count for _, count in top_10_covered]\n",
    "betweenness_centrality_results_new = matches_unique[['org_art_name', 'org_art_id']].copy()\n",
    "betweenness_centrality_results_new.columns = ['original_name', 'artist_id']\n",
    "print(betweenness_centrality_results_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67890581",
   "metadata": {},
   "source": [
    "Network Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2be4504f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Metric                     Value\n",
      " Number of vertices (artists)                     76356\n",
      "Number of edges (song covers)                    499454\n",
      "         Number of components                     18153\n",
      " Average shortest path length N/A (graph not connected)\n",
      "                      Density                  0.000086\n"
     ]
    }
   ],
   "source": [
    "# Basic stats\n",
    "num_nodes = G.number_of_nodes()\n",
    "num_edges = G.number_of_edges()\n",
    "density = nx.density(G)\n",
    "\n",
    "# Components (weakly connected components for directed graph)\n",
    "num_components = nx.number_weakly_connected_components(G)\n",
    "\n",
    "# Average shortest path length (only valid on strongly connected graphs or components)\n",
    "# We'll use the largest weakly connected component\n",
    "largest_cc = max(nx.weakly_connected_components(G), key=len)\n",
    "G_sub = G.subgraph(largest_cc)\n",
    "try:\n",
    "    avg_shortest_path = nx.average_shortest_path_length(G_sub)\n",
    "except:\n",
    "    avg_shortest_path = \"N/A (graph not connected)\"\n",
    "\n",
    "# Create a table\n",
    "metrics = {\n",
    "    \"Metric\": [\n",
    "        \"Number of vertices (artists)\",\n",
    "        \"Number of edges (song covers)\",\n",
    "        \"Number of components\",\n",
    "        \"Average shortest path length\",\n",
    "        \"Density\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        num_nodes,\n",
    "        num_edges,\n",
    "        num_components,\n",
    "        avg_shortest_path,\n",
    "        density\n",
    "    ]\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "print(metrics_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
